"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Img2TextModel = void 0;
const common_js_1 = require("../common.js");
const index_js_1 = require("../index.js");
const base_js_1 = require("./base.js");
const text_js_1 = require("../text.js");
const image_js_1 = require("../image.js");
class Img2TextModel extends base_js_1.BaseMultimodalModel {
    constructor(metadata) {
        super(metadata);
        this.init = async (proxy = true) => {
            const start = new Date();
            const imageEncoderPath = this.metadata.modelPaths.get("image-encoder");
            if (!imageEncoderPath) {
                throw new Error("model paths do not have the 'image-encoder' path");
            }
            const imageEncoderOutputName = this.metadata.outputNames?.get("image-encoder");
            if (!imageEncoderOutputName) {
                throw new Error("output names do not have the 'encoder' path");
            }
            const imageEncoderSession = await (0, index_js_1.createSession)(imageEncoderPath, proxy);
            this.imageEncoder = new common_js_1.Encoder(imageEncoderSession, imageEncoderOutputName, common_js_1.GeneratorType.Img2Seq);
            if (this.metadata.modelPaths.has("text-encoder")) {
                const textEncoderPath = this.metadata.modelPaths.get("text-encoder");
                if (!textEncoderPath) {
                    throw new Error("model paths do not have the 'text-encoder' path");
                }
                const textEncoderOutputName = this.metadata.outputNames?.get("text-encoder");
                if (!textEncoderOutputName) {
                    throw new Error("output names do not have the 'encoder' path");
                }
                const textEncoderSession = await (0, index_js_1.createSession)(textEncoderPath, proxy);
                this.textEncoder = new common_js_1.Encoder(textEncoderSession, textEncoderOutputName, common_js_1.GeneratorType.Seq2Seq);
            }
            const decoderPath = this.metadata.modelPaths.get("text-decoder");
            if (!decoderPath) {
                throw new Error("model paths do not have the 'text-decoder' path");
            }
            const decoderOutputName = this.metadata.outputNames?.get("text-decoder");
            if (!decoderOutputName) {
                throw new Error("output names do not have the 'text-decoder' path");
            }
            const decoderSession = await (0, index_js_1.createSession)(decoderPath, proxy);
            this.textDecoder = new common_js_1.Decoder(decoderSession, decoderOutputName, common_js_1.GeneratorType.Img2Seq);
            const preprocessorConfig = await image_js_1.PreprocessorConfig.fromFile(this.metadata.preprocessorPath);
            this.preprocessor = new image_js_1.Preprocessor(preprocessorConfig);
            this.tokenizer = await (0, index_js_1.loadTokenizer)(this.metadata.tokenizerPath);
            const end = new Date();
            const elapsed = (end.getTime() - start.getTime()) / 1000;
            this.initialized = true;
            return elapsed;
        };
        this.process = async (imageInputs, textInputs) => {
            if (!this.initialized ||
                !this.imageEncoder ||
                !this.textDecoder ||
                !this.tokenizer) {
                throw Error("the model is not initialized");
            }
            const start = new Date();
            if (typeof imageInputs === "string") {
                imageInputs = [imageInputs];
            }
            if (typeof textInputs === "string") {
                textInputs = [textInputs];
            }
            const imageTensor = await (0, image_js_1.prepareImagesTensor)(imageInputs, this.preprocessor);
            if (this.metadata.tokenizerParams.bosTokenID === undefined ||
                this.metadata.tokenizerParams.eosTokenID === undefined) {
                throw Error("the model does not have the bosTokenID or eosTokenID");
            }
            const textTensors = await (0, text_js_1.prepareTextTensors)(textInputs, this.tokenizer, false, this.metadata.tokenizerParams.padTokenID, this.metadata.tokenizerParams.bosTokenID);
            const generationConfig = {
                maxLength: 500,
                eosTokenID: this.metadata.tokenizerParams.eosTokenID,
                bosTokenID: this.metadata.tokenizerParams.bosTokenID,
                padTokenID: this.metadata.tokenizerParams.padTokenID,
            };
            const outputTokenIDs = [];
            const result = [];
            let encoderOutput;
            let generateFunc;
            if (this.textEncoder) {
                encoderOutput = await (0, common_js_1.encodeData)(this.imageEncoder, imageTensor, undefined, this.textEncoder, textTensors[0], textTensors[1]);
                generateFunc = (0, common_js_1.generate)(encoderOutput, this.textDecoder, generationConfig);
            }
            else {
                encoderOutput = await (0, common_js_1.encodeData)(this.imageEncoder, imageTensor);
                generateFunc = (0, common_js_1.generate)(encoderOutput, this.textDecoder, generationConfig, undefined, textTensors[0], textTensors[1]);
            }
            for await (const tokenIDs of generateFunc) {
                for (let i = 0; i < tokenIDs.length; i++) {
                    if (tokenIDs[i] !== this.metadata.tokenizerParams.padTokenID) {
                        if (!outputTokenIDs[i])
                            outputTokenIDs[i] = [];
                        outputTokenIDs[i].push(tokenIDs[i]);
                    }
                    const outputTokens = new Uint32Array(outputTokenIDs[i]);
                    const output = (await this.tokenizer.decode(outputTokens, true)).trim();
                    result[i] = output;
                }
            }
            const end = new Date();
            const elapsed = (end.getTime() - start.getTime()) / 1000;
            return {
                text: result,
                elapsed: elapsed,
            };
        };
    }
    async *processStream(imageInputs, textInputs) {
        if (!this.initialized ||
            !this.imageEncoder ||
            !this.textDecoder ||
            !this.tokenizer) {
            throw Error("the model is not initialized");
        }
        if (typeof imageInputs === "string") {
            imageInputs = [imageInputs];
        }
        if (typeof textInputs === "string") {
            textInputs = [textInputs];
        }
        const imageTensor = await (0, image_js_1.prepareImagesTensor)(imageInputs, this.preprocessor);
        const textTensors = await (0, text_js_1.prepareTextTensors)(textInputs, this.tokenizer, false, this.metadata.tokenizerParams.padTokenID, this.metadata.tokenizerParams.bosTokenID);
        if (this.metadata.tokenizerParams.bosTokenID === undefined ||
            this.metadata.tokenizerParams.eosTokenID === undefined) {
            throw Error("the model does not have the bosTokenID or eosTokenID");
        }
        const generationConfig = {
            maxLength: 500,
            eosTokenID: this.metadata.tokenizerParams.eosTokenID,
            bosTokenID: this.metadata.tokenizerParams.bosTokenID,
            padTokenID: this.metadata.tokenizerParams.padTokenID,
        };
        const outputTokenIDs = [];
        let oldOutput = new Array(textInputs.length).fill("");
        const diffs = new Array(textInputs.length).fill("");
        let encoderOutput;
        let generateFunc;
        if (this.textEncoder) {
            encoderOutput = await (0, common_js_1.encodeData)(this.imageEncoder, imageTensor, undefined, this.textEncoder, textTensors[0], textTensors[1]);
            generateFunc = (0, common_js_1.generate)(encoderOutput, this.textDecoder, generationConfig);
        }
        else {
            encoderOutput = await (0, common_js_1.encodeData)(this.imageEncoder, imageTensor);
            generateFunc = (0, common_js_1.generate)(encoderOutput, this.textDecoder, generationConfig, undefined, textTensors[0], textTensors[1]);
        }
        for await (const tokenIDs of generateFunc) {
            const newOutput = [];
            for (let i = 0; i < tokenIDs.length; i++) {
                if (tokenIDs[i] !== this.metadata.tokenizerParams.padTokenID) {
                    if (!outputTokenIDs[i])
                        outputTokenIDs[i] = [];
                    outputTokenIDs[i].push(tokenIDs[i]);
                }
                const outputTokens = new Uint32Array(outputTokenIDs[i]);
                const output = await this.tokenizer.decode(outputTokens, true);
                newOutput.push(output);
                diffs[i] = output.substring(oldOutput[i].length);
            }
            yield diffs;
            oldOutput = newOutput;
        }
    }
}
exports.Img2TextModel = Img2TextModel;
//# sourceMappingURL=img2text.js.map