"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.ZeroShotClassificationModel = void 0;
const ort = __importStar(require("onnxruntime-common"));
const image_js_1 = require("../image.js");
const text_js_1 = require("../text.js");
const base_js_1 = require("./base.js");
const common_js_1 = require("../common.js");
class ZeroShotClassificationModel extends base_js_1.BaseMultimodalModel {
    constructor() {
        super(...arguments);
        this.process = async (inputs, classes) => {
            if (!this.initialized || !this.preprocessor || !this.tokenizer) {
                throw Error("the model is not initialized");
            }
            if (typeof inputs === "string") {
                inputs = [inputs];
            }
            const start = new Date();
            const imageTensor = await (0, image_js_1.prepareImagesTensor)(inputs, this.preprocessor);
            const textTensors = await (0, text_js_1.prepareTextTensors)(classes, this.tokenizer, true, this.metadata.tokenizerParams.padTokenID);
            const [imageEmbeds, textEmbeds] = await Promise.all([
                this.imageInference(imageTensor),
                this.textInference(textTensors[0], textTensors[1]),
            ]);
            const result = await this.generateLogits(textEmbeds, imageEmbeds, classes);
            const end = new Date();
            const elapsed = (end.getTime() - start.getTime()) / 1000;
            result.elapsed = elapsed;
            return result;
        };
        this.embedImages = async (inputs) => {
            if (!this.initialized || !this.preprocessor || !this.tokenizer) {
                throw Error("the model is not initialized");
            }
            if (typeof inputs === "string") {
                inputs = [inputs];
            }
            const imageTensor = await (0, image_js_1.prepareImagesTensor)(inputs, this.preprocessor);
            const imageEmbeds = await this.imageInference(imageTensor);
            return imageEmbeds.embedding;
        };
        this.embedTexts = async (inputs) => {
            if (!this.initialized || !this.tokenizer) {
                throw Error("the model is not initialized");
            }
            if (typeof inputs === "string") {
                inputs = [inputs];
            }
            const textTensors = await (0, text_js_1.prepareTextTensors)(inputs, this.tokenizer, true, this.metadata.tokenizerParams.padTokenID);
            const textEmbeds = await this.textInference(textTensors[0], textTensors[1]);
            return textEmbeds.embedding;
        };
        this.imageInference = async (imageInput) => {
            if (!this.initialized || !this.sessions) {
                throw Error("the model is not initialized");
            }
            const feeds = {};
            feeds["pixel_values"] = imageInput;
            const session = this.sessions.get("image");
            if (!session) {
                throw Error("the image model is absent in the sessions map");
            }
            const outputData = await session.run(feeds);
            const outputNames = await session.outputNames();
            if (!outputNames.includes("image_embeds")) {
                throw Error("the image model does not contain image_embeds output");
            }
            let imageEmbeds = [];
            imageEmbeds = new Array(outputData["image_embeds"].dims[0]);
            const tensor = new common_js_1.Tensor(outputData["image_embeds"]);
            for (let i = 0; i < outputData["image_embeds"].dims[0]; i++) {
                imageEmbeds[i] = new Array(outputData["image_embeds"].dims[1]);
                for (let j = 0; j < outputData["image_embeds"].dims[1]; j++) {
                    imageEmbeds[i][j] = tensor.at([i, j]);
                }
            }
            for (let i = 0; i < imageEmbeds.length; i++) {
                imageEmbeds[i] = (0, image_js_1.normalize)(imageEmbeds[i]);
            }
            return {
                embedding: imageEmbeds,
                outputTensor: outputData["image_embeds"],
            };
        };
        this.textInference = async (inputIDs, attentionMask) => {
            if (!this.initialized || !this.sessions) {
                throw Error("the model is not initialized");
            }
            const feeds = {};
            feeds["input_ids"] = inputIDs;
            feeds["attention_mask"] = attentionMask;
            const session = this.sessions.get("text");
            if (!session) {
                throw Error("the text model is absent in the sessions map");
            }
            const outputData = await session.run(feeds);
            const outputNames = await session.outputNames();
            if (!outputNames.includes("text_embeds")) {
                throw Error("the model does not contain text_embeds output");
            }
            let textEmbeds = [];
            const tensor = new common_js_1.Tensor(outputData["text_embeds"]);
            textEmbeds = new Array(outputData["text_embeds"].dims[0]);
            for (let i = 0; i < outputData["text_embeds"].dims[0]; i++) {
                textEmbeds[i] = new Array(outputData["text_embeds"].dims[1]);
                for (let j = 0; j < outputData["text_embeds"].dims[1]; j++) {
                    textEmbeds[i][j] = tensor.at([i, j]);
                }
            }
            for (let i = 0; i < textEmbeds.length; i++) {
                textEmbeds[i] = (0, image_js_1.normalize)(textEmbeds[i]);
            }
            return {
                embedding: textEmbeds,
                outputTensor: outputData["text_embeds"],
            };
        };
        this.imageLogits = async (imageEmbeds, textEmbeds) => {
            if (!this.initialized || !this.sessions) {
                throw Error("the model is not initialized");
            }
            const feeds = {};
            feeds["text_embeds"] = new ort.Tensor(Float32Array.from(textEmbeds.flat()), [textEmbeds.length, textEmbeds[0].length]);
            feeds["image_embeds"] = new ort.Tensor(Float32Array.from(imageEmbeds.flat()), [imageEmbeds.length, imageEmbeds[0].length]);
            const session = this.sessions.get("combine");
            if (!session) {
                throw Error("the combine model is absent in the sessions map");
            }
            const outputData = await session.run(feeds);
            const outputNames = await session.outputNames();
            if (!outputNames.includes("logits_per_image")) {
                throw Error("the model does not contain logits_per_image output");
            }
            const logits = outputData["logits_per_image"];
            const predictions = [];
            for (let i = 0; i < logits.dims[0]; i++) {
                const sm = (0, image_js_1.softmax)(
                // eslint-disable-next-line @typescript-eslint/ban-ts-comment
                // @ts-ignore
                logits.data.slice(i * logits.dims[1], (i + 1) * logits.dims[1]));
                predictions.push(sm);
            }
            return predictions;
        };
        this.generateLogits = async (textResults, imageResults, classes) => {
            if (!this.initialized || !this.sessions) {
                throw Error("the model is not initialized");
            }
            const feeds = {};
            feeds["text_embeds"] = textResults.outputTensor;
            feeds["image_embeds"] = imageResults.outputTensor;
            const session = this.sessions.get("combine");
            if (!session) {
                throw Error("the combine model is absent in the sessions map");
            }
            const outputData = await session.run(feeds);
            const outputNames = await session.outputNames();
            if (!outputNames.includes("logits_per_image")) {
                throw Error("the model does not contain logits_per_image output");
            }
            const logits = outputData["logits_per_image"];
            const predictions = [];
            for (let i = 0; i < logits.dims[0]; i++) {
                const res = new Array(classes.length).fill({
                    class: "unknown",
                    confidence: 0,
                });
                const sm = (0, image_js_1.softmax)(
                // eslint-disable-next-line @typescript-eslint/ban-ts-comment
                // @ts-ignore
                logits.data.slice(i * logits.dims[1], (i + 1) * logits.dims[1]));
                for (let i = 0; i < sm.length; i++) {
                    res[i] = {
                        class: classes[i],
                        confidence: sm[i],
                    };
                }
                res.sort((a, b) => b.confidence - a.confidence);
                predictions.push(res);
            }
            const result = {
                results: predictions,
                imageFeatures: imageResults.embedding,
                textFeatures: textResults.embedding,
                elapsed: 0,
            };
            if (predictions.length === 1) {
                result.results = predictions[0];
            }
            return result;
        };
    }
}
exports.ZeroShotClassificationModel = ZeroShotClassificationModel;
//# sourceMappingURL=zeroShot.js.map